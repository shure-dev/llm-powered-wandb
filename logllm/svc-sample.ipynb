{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample code how to use `logllm` package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your (messy) machine learning code is here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Confusion Matrix (excluding Class 1):\n",
      "[[10]]\n",
      "\n",
      "Detailed Classification Report (excluding certain classes):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0     1.0000    1.0000    1.0000        10\n",
      "\n",
      "    accuracy                         1.0000        10\n",
      "   macro avg     1.0000    1.0000    1.0000        10\n",
      "weighted avg     1.0000    1.0000    1.0000        10\n",
      "\n",
      "\n",
      "Note: Class 1 was intentionally excluded from the evaluation.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets as ds\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.svm import SVC as SupportVectorClassifier\n",
    "from sklearn.metrics import confusion_matrix as cm, classification_report as cr\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "iris_dataset = ds.load_iris()\n",
    "\n",
    "# Binarize the class labels (exclude Class 2)\n",
    "features = iris_dataset.data[iris_dataset.target != 2]  \n",
    "labels = iris_dataset.target[iris_dataset.target != 2]  \n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data, train_labels, test_labels = tts(\n",
    "    features, \n",
    "    labels, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    shuffle=True, \n",
    "    stratify=labels  \n",
    ")\n",
    "\n",
    "# Initialize and configure the Support Vector Machine model\n",
    "svc_model = SupportVectorClassifier(\n",
    "    C=1.0,        \n",
    "    kernel='linear', \n",
    "    degree=3,     \n",
    "    gamma='auto', \n",
    "    coef0=0.0,    \n",
    "    shrinking=True,\n",
    "    probability=False, \n",
    "    tol=1e-3,     \n",
    "    cache_size=200, \n",
    "    class_weight=None,\n",
    "    verbose=False, \n",
    "    max_iter=-1,  \n",
    "    decision_function_shape='ovr',\n",
    "    break_ties=False, \n",
    "    random_state=None\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "svc_model.fit(train_data, train_labels)\n",
    "\n",
    "# Obtain the predicted results for the test data\n",
    "predicted_labels = svc_model.predict(test_data)\n",
    "\n",
    "# Create the confusion matrix\n",
    "conf_matrix = cm(test_labels, predicted_labels)\n",
    "\n",
    "# Define evaluation labels (intentionally exclude Class 1)\n",
    "excluded_class = 1\n",
    "classes_to_evaluate = [cls for cls in np.unique(test_labels) if cls != excluded_class]\n",
    "\n",
    "# Calculate confusion matrix with the excluded class removed\n",
    "conf_matrix_filtered = np.array([\n",
    "    [conf_matrix[i, j] for j in range(len(conf_matrix)) if j != excluded_class]\n",
    "    for i in range(len(conf_matrix)) if i != excluded_class\n",
    "])\n",
    "\n",
    "# Filter true labels and predicted labels (only keep the evaluated classes)\n",
    "filtered_test_labels = [label for label in test_labels if label in classes_to_evaluate]\n",
    "filtered_predicted_labels = [pred for pred in predicted_labels if pred in classes_to_evaluate]\n",
    "\n",
    "# Output a detailed classification report (excluding the specified class)\n",
    "classification_report_filtered = cr(\n",
    "    filtered_test_labels, \n",
    "    filtered_predicted_labels, \n",
    "    labels=classes_to_evaluate,\n",
    "    target_names=[f\"Class {cls}\" for cls in classes_to_evaluate],\n",
    "    digits=4,\n",
    "    output_dict=False,\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "# Display the complex evaluation results\n",
    "print(f\"Filtered Confusion Matrix (excluding Class {excluded_class}):\\n{conf_matrix_filtered}\")\n",
    "print(\"\\nDetailed Classification Report (excluding certain classes):\")\n",
    "print(classification_report_filtered)\n",
    "\n",
    "# Provide a note regarding the intentionally excluded class\n",
    "if excluded_class in np.unique(test_labels):\n",
    "    print(f\"\\nNote: Class {excluded_class} was intentionally excluded from the evaluation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start logging with `logllm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from Google Generative AI processed and logged to W&B.\n",
      "Dictionary:  \n"
     ]
    }
   ],
   "source": [
    "from logllm.log_llm import log_llm\n",
    "\n",
    "notebook_path = \"svc-sample.ipynb\" # Here is target file to log\n",
    "\n",
    "log_llm(notebook_path,is_logging=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected condition with GPT4 from the script\n",
    "\n",
    "```Python\n",
    "{\n",
    "    \"method\": \"SVC\",\n",
    "    \"dataset\": \"Iris\",\n",
    "    \"task\": \"classification\",\n",
    "    \"accuracy\": 1.0,\n",
    "    \"C\": 1.0,\n",
    "    \"degree\": 3,\n",
    "    \"tol\": 0.001,\n",
    "    \"cache_size\": 200,\n",
    "    \"max_iter\": -1,\n",
    "    \"test_size\": 0.2,\n",
    "    \"random_state\": 42,\n",
    "    \"kernel\": \"linear\",\n",
    "    \"condition_as_natural_langauge\": [\n",
    "        \"Using linear kernel on SVC model.\",\n",
    "        \"Excluding class 2 from Iris dataset.\",\n",
    "        \"Splitting data into 80% training and 20% testing.\"\n",
    "    ],\n",
    "    \"advice_to_improve_acc\": [\n",
    "        \"Consider using cross-validation for better performance evaluation.\",\n",
    "        \"Experiment with different kernels to optimize results.\",\n",
    "        \"Increase the dataset size to improve generalization.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GenerativeModel.start_chat() got an unexpected keyword argument 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlogllm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquery\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m query\n\u001b[1;32m      3\u001b[0m notebook_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvc-sample.ipynb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# Here is target file to log\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m query(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhat is  the best model?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/vscode/logllm/logllm/query.py:18\u001b[0m, in \u001b[0;36mquery\u001b[0;34m(user_input)\u001b[0m\n\u001b[1;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39mGenerativeModel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini-1.5-flash\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m system_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124m    # Convert the following query to a W&B API query:\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m user_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;124m# Here is a user\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms :\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_input\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     21\u001b[0m response \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mstart_chat(\n\u001b[1;32m     22\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini-1.5-flash\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m     history\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     ]\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[0;31mTypeError\u001b[0m: GenerativeModel.start_chat() got an unexpected keyword argument 'model'"
     ]
    }
   ],
   "source": [
    "from logllm.query import query\n",
    "\n",
    "notebook_path = \"svc-sample.ipynb\" # Here is target file to log\n",
    "\n",
    "query(\"what is  the best model?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
